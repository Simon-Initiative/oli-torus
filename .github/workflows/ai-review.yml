name: ai-review
on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  workflow_dispatch:

jobs:
  changes:
    name: detect/changes
    runs-on: ubuntu-latest
    outputs:
      elixir: ${{ steps.filter.outputs.elixir }}
      typescript: ${{ steps.filter.outputs.typescript }}
      ui: ${{ steps.filter.outputs.ui }}
      requirements: ${{ steps.filter.outputs.requirements }}
      security: ${{ steps.filter.outputs.security }}
      performance: ${{ steps.filter.outputs.performance }}
      roles: ${{ steps.build_matrix.outputs.roles }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - name: Debug changed files
        run: |
          echo "Base ref: ${{ github.base_ref }} | Head ref: ${{ github.head_ref }}"
          git fetch origin ${{ github.base_ref }} --depth=1 || true
          echo "Changed files (GitHub API reports): ${{ github.event.pull_request.changed_files }}"
          echo "Changed files (git diff --name-only):"
          git diff --name-only origin/${{ github.base_ref }}...HEAD || true
      - id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            elixir:
              - 'lib/**/*.ex'
              - 'lib/**/*.exs'
              - 'test/**/*.exs'
            typescript:
              - 'assets/src/**/*.ts'
              - 'assets/src/**/*.tsx'
            ui:
              - 'assets/src/**/*'
              - 'lib/**/*.heex'
              - 'lib/**/*.leex'
              - 'lib/**/live/**/*.ex'
            requirements:
              - 'docs/features/**'
              - '.review/**'
            security:
              - 'lib/**/plugs/**'
              - 'lib/oli_web/user_auth.ex'
              - 'lib/oli/accounts/**'
              - 'lib/oli/lti/**'
              - 'config/**'
            performance:
              - 'lib/oli/delivery/**'
              - 'lib/oli/publishing/**'
              - 'lib/oli/resources/**'
              - 'lib/oli/activities/**'

      - id: build_matrix
        name: Build matrix roles
        shell: bash
        run: |
          roles=()
          [[ "${{ steps.filter.outputs.elixir }}" == 'true' ]] && roles+=("elixir")
          [[ "${{ steps.filter.outputs.typescript }}" == 'true' ]] && roles+=("typescript")
          [[ "${{ steps.filter.outputs.ui }}" == 'true' ]] && roles+=("ui")
          [[ "${{ steps.filter.outputs.security }}" == 'true' ]] && roles+=("security")
          [[ "${{ steps.filter.outputs.performance }}" == 'true' ]] && roles+=("performance")
          [[ "${{ steps.filter.outputs.requirements }}" == 'true' ]] && roles+=("requirements")
          # Ensure at least one role runs; default to 'requirements'
          if [ ${#roles[@]} -eq 0 ]; then roles+=("requirements"); fi
          # Always run performance and security; de-duplicate at JSON stage
          json=$(printf '%s\n' "${roles[@]}" performance security | jq -R . | jq -c -s 'unique')
          echo "roles=${json}" >> "$GITHUB_OUTPUT"

  specialist:
    name: ai/${{ matrix.role }}
    runs-on: ubuntu-latest
    needs: [changes]
    strategy:
      matrix:
        role: ${{ fromJSON(needs.changes.outputs.roles) }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # ensure history for robust diffs/merge-base
      - name: Echo role being run
        run: |
          echo "Running reviewer role: ${{ matrix.role }}"
          echo "Filter outputs: elixir=${{ needs.changes.outputs.elixir }}, ts=${{ needs.changes.outputs.typescript }}, ui=${{ needs.changes.outputs.ui }}, perf=${{ needs.changes.outputs.performance }}, sec=${{ needs.changes.outputs.security }}, req=${{ needs.changes.outputs.requirements }}"

      - name: Generate PR diff
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            BASE="${{ github.event.pull_request.base.sha }}"
            HEADSHA="${{ github.event.pull_request.head.sha }}"
          else
            BASE=$(git rev-parse HEAD^)
            HEADSHA=$(git rev-parse HEAD)
          fi
          # Fetch the exact SHAs (works with forks and shallow clones)
          git fetch --no-tags --prune --depth=1 origin "+${BASE}" "+${HEADSHA}"
          # Produce a diff between the two trees (no merge-base required)
          git diff --unified=0 "${BASE}" "${HEADSHA}" > diff.patch
          # Ensure file exists (do not truncate if already written)
          [ -f diff.patch ] || touch diff.patch

        run: |
          set -euo pipefail
          mkdir -p ai
          # chmod -R a-w .
          # chmod u+w ai

      - name: Install Codex CLI
        run: npm i -g @openai/codex

      - name: Run Codex reviewer (diff-first, self-serve context)
        id: run
        shell: bash
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          IS_FORK: ${{ github.event.pull_request.head.repo.fork }}
          OPENAI_ORG_KEY: ${{ secrets.OPENAI_ORG_KEY }}
        run: |
          set -euo pipefail
          ROLE="${{ matrix.role }}"
          export ROLE

          {
            echo "You are a specialist reviewer for ${ROLE}.";
            echo "PRIMARY SOURCE: the DIFF below.";
            echo "If the DIFF is insufficient to judge correctness/safety, you MAY open files in the workspace to gather LIMITED context.";
            echo "ALLOWED PATHS: lib/**, assets/src/**, config/**, priv/repo/migrations/**";
            echo "DENYLIST: node_modules/**, deps/**, build/**, _build/**, .git/**";
            echo "Limits: at most 5 extra files total, and ≤1000 lines per file. Prefer narrow ranges near the changed lines.";
            echo "";
            echo "Return ONLY strict JSON matching .review/CONTRACT.json, extended with:";
            echo '  "context_used": [{"path":"","lines":"L10-L80"}]';
            echo "If you cannot produce valid JSON, output this minimal object:";
            echo '{"verdict":"warn","confidence":0.3,"summary":"Could not parse; returning minimal","findings":[],"context_used":[]}';
            echo "";
            echo "Rules:";
            echo "- Focus on changed lines; use extra context only when necessary.";
            echo "- Fail only for truly blocking issues; include file+line and a concrete fix.";
            echo "- Confidence = 0..1.";
            echo "";
            echo "---CHECKLIST START---";
            [ -f ".review/${ROLE}.md" ] && cat ".review/${ROLE}.md" || echo "(no checklist for ${ROLE})";
            echo "---CHECKLIST END---";
            echo "---DIFF START---";
            head -c 150000 diff.patch;
            echo "---DIFF END---";
          } > ai/prompt.${ROLE}.txt

          echo "DIFF size (bytes): $(wc -c < diff.patch || echo 0)"
          echo "PROMPT size (bytes): $(wc -c < ai/prompt.${ROLE}.txt || echo 0)"

          echo "::group::AI Prompt (${ROLE}) — first 4000 bytes"
          head -c 4000 ai/prompt.${ROLE}.txt || true; echo
          echo "..."
          echo "AI Prompt (${ROLE}) — last 2000 bytes"
          tail -c 2000 ai/prompt.${ROLE}.txt || true; echo
          echo "::endgroup::"

          # Run Codex reviewer (non-streaming output). Some versions don't support --no-stream;
          # relying on default behavior with --stdin and --format json.
          # Feed prompt via STDIN (portable across Codex CLI versions)
          # If diff is empty, short-circuit with a PASS
          if [[ ! -s diff.patch ]]; then
            echo '{"verdict":"pass","confidence":0.8,"summary":"Empty diff","findings":[],"context_used":[]}' > ai/${ROLE}.json
            exit 0
          fi

          # Fork/secret guard: on forks or missing key, emit WARN and skip Codex
          if [ "${IS_FORK:-false}" = "true" ] || [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "Forked PR or missing OPENAI_API_KEY; emitting WARN and skipping Codex."
            printf '%s\n' \
              '{' \
              '  "verdict": "warn",' \
              '  "confidence": 0.2,' \
              '  "summary": "AI reviewer skipped (forked PR or missing OPENAI_API_KEY).",' \
              '  "findings": [],' \
              '  "context_used": []' \
              '}' > ai/${ROLE}.json
            exit 0
          fi

          # Ensure Codex config dir under HOME is writable and exists
          mkdir -p "$HOME/.config/codex"
          : > "$HOME/.config/codex/config.json" || true
          : > "$HOME/.config/codex/config.md" || true

          KEY="${OPENAI_API_KEY}"
          export OPENAI_API_KEY="$KEY"
          echo "Codex binary: $(command -v codex || echo 'not found')"
          codex --version || true

          # Headless login per docs; if login fails, emit a FAIL JSON and stop
          if ! codex login --api-key "$KEY" 2> ai/${ROLE}.login.err; then
            echo "Codex login failed; capturing stderr and emitting FAIL JSON."
            err=$(head -c 300 ai/${ROLE}.login.err | sed 's/"/\\"/g')
            printf '%s\n' \
              '{' \
              '  "verdict": "fail",' \
              '  "confidence": 1.0,' \
              "  \"summary\": \"Codex login failed. $err\"," \
              '  "findings": [' \
              '    {' \
              '      "path": ".github/workflows/ai-review.yml",' \
              '      "line": 1,' \
              '      "severity": "high",' \
              '      "title": "Codex login failed",' \
              '      "advice": "Verify OPENAI_API_KEY secret and that Codex CLI can write ~/.config/codex."' \
              '    }' \
              '  ],' \
              '  "context_used": []' \
              '}' > ai/${ROLE}.json
            exit 0
          fi

          codex exec --full-auto < ai/prompt.${ROLE}.txt > ai/${ROLE}.raw.txt || true

          # If auth failed, create a clear failing JSON so the dev knows what to fix
          if grep -qi "401 Unauthorized" ai/${ROLE}.raw.txt; then
            echo "AI reviewer authentication failed (401). Emitting blocking JSON with guidance."
            printf '%s\n' \
              '{' \
              '  "verdict": "fail",' \
              '  "confidence": 1.0,' \
              '  "summary": "AI reviewer authentication failed (401). Ensure OPENAI_API_KEY is configured for this workflow/run. Forked PRs do not receive secrets.",' \
              '  "findings": [' \
              '    {' \
              '      "path": ".github/workflows/ai-review.yml",' \
              '      "line": 1,' \
              '      "severity": "high",' \
              '      "title": "AI reviewer auth failed (401)",' \
              '      "advice": "Set repo/Org secret OPENAI_API_KEY; guard Codex step for forks (no secrets)."' \
              '    }' \
              '  ],' \
              '  "context_used": []' \
              '}' > ai/${ROLE}.json
            exit 0
          fi

          echo "RAW size (bytes): $(wc -c < ai/${ROLE}.raw.txt || echo 0)"
          echo "::group::AI Raw Output (${ROLE}) — first 4000 bytes"
          head -c 4000 ai/${ROLE}.raw.txt || true; echo
          echo "..."
          echo "AI Raw Output (${ROLE}) — last 2000 bytes"
          tail -c 2000 ai/${ROLE}.raw.txt || true; echo
          echo "::endgroup::"

          # Extract the first JSON object from output robustly.
          node -e '
            const fs=require("fs");
            const role=process.env.ROLE;
            if(!role){ console.error("ROLE env missing"); process.exit(2); }
            const fallback = { verdict: "warn", confidence: 0.3, summary: "AI output missing JSON; fallback applied", findings: [], context_used: [] };
            try {
              const raw=fs.readFileSync(`ai/${role}.raw.txt`,`utf8`);
              const m=raw.match(/\{[\s\S]*?\}/);
              if(!m){ fs.writeFileSync(`ai/${role}.json`, JSON.stringify(fallback)); process.exit(0); }
              const obj = JSON.parse(m[0]);
              if(!obj || !obj.verdict){ fs.writeFileSync(`ai/${role}.json`, JSON.stringify(fallback)); process.exit(0); }
              fs.writeFileSync(`ai/${role}.json`, JSON.stringify(obj));
            } catch(e) {
              fs.writeFileSync(`ai/${role}.json`, JSON.stringify(fallback));
            }
          '

      - name: Validate JSON against contract
        run: |
          node -e '
            const fs=require("fs");
            const s=JSON.parse(fs.readFileSync("ai/${{ matrix.role }}.json","utf8"));
            if(!["pass","warn","fail"].includes(s.verdict)) process.exit(3);
          '

      - uses: actions/upload-artifact@v4
        with:
          name: ai-results-${{ matrix.role }}
          path: ai/${{ matrix.role }}.json
          if-no-files-found: error

      - name: Upload AI debug artifacts (prompt + raw)
        uses: actions/upload-artifact@v4
        with:
          name: ai-debug-${{ matrix.role }}
          path: |
            ai/prompt.${{ matrix.role }}.txt
            ai/${{ matrix.role }}.raw.txt
          if-no-files-found: warn

      - name: Ensure no repo changes (tracked files only)
        run: |
          git status --porcelain --untracked-files=no
          test -z "$(git status --porcelain --untracked-files=no)" || (echo "Workspace mutated!"; git --no-pager diff; exit 1)

  aggregate:
    name: ai/review
    runs-on: ubuntu-latest
    needs: [specialist]
    steps:
      - uses: actions/download-artifact@v4
        with:
          pattern: ai-results-*
          path: ai
          merge-multiple: true

      - uses: actions/download-artifact@v4
        with:
          pattern: ai-debug-*
          path: ai-debug
          merge-multiple: true

      - name: Aggregate & decide
        id: agg
        run: |
          node -e '
            const fs=require("fs"), path=require("path");
            const files=fs.readdirSync("ai").filter(f=>f.endsWith(".json"));
            const results=files.map(f=>({role:f.replace(".json",""), ...JSON.parse(fs.readFileSync(path.join("ai",f),"utf8"))}));
            // Strict policy: fail if any fail with confidence >= 0.6 OR 2+ warns
            const fails=results.filter(r=>r.verdict==="fail" && r.confidence>=0.6);
            const warns=results.filter(r=>r.verdict==="warn");
            const status = (fails.length || warns.length>=2) ? "fail" : "pass";

            const lines=[`### AI Review Summary`, `Status: **${status.toUpperCase()}**`, ""];
            for(const r of results){
              lines.push(`- **${r.role}**: ${r.verdict} (conf ${r.confidence}) — ${(r.findings?.length||0)} findings`);
              const findings = Array.isArray(r.findings)? r.findings: [];
              if(findings.length){
                const top = findings.slice(0,10);
                for(const f of top){
                  lines.push(`  - ${f.severity||""} ${f.path||"?"}:${f.line||"?"} — ${f.title||"(no title)"}`);
                  if(f.advice){ lines.push(`    > ${f.advice.replace(/\n/g, " ")}`); }
                }
                if(findings.length>10){ lines.push(`  - … ${findings.length-10} more findings`); }
              }
              // Attach raw/prompt snippets when available
              try{
                const promptPath = path.join("ai-debug", `prompt.${r.role}.txt`);
                const rawPath = path.join("ai-debug", `${r.role}.raw.txt`);
                const hasPrompt = fs.existsSync(promptPath);
                const hasRaw = fs.existsSync(rawPath);
                if(hasPrompt || hasRaw){
                  lines.push("  <details><summary>AI debug (prompt/raw)</summary>");
                  if(hasPrompt){
                    const p = fs.readFileSync(promptPath, "utf8");
                    lines.push("\n  Prompt (first 600 chars):\n\n");
                    lines.push("```\n" + p.slice(0,600) + (p.length>600?"…":"") + "\n```");
                  }
                  if(hasRaw){
                    const rv = fs.readFileSync(rawPath, "utf8");
                    lines.push("\n  Raw (first 600 chars):\n\n");
                    lines.push("```\n" + rv.slice(0,600) + (rv.length>600?"…":"") + "\n```");
                  }
                  lines.push("  </details>");
                }
              }catch(e){}
            }
            const md = lines.join("\n");
            fs.writeFileSync("ai/verdict.json", JSON.stringify({status, results, markdown: md}, null, 2));
          '

      - name: Post single summary comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const v = JSON.parse(fs.readFileSync('ai/verdict.json','utf8'));
            // one tidy summary comment
            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: v.markdown
            });

      - name: Convert findings to annotations (optional)
        run: |
          node -e '
            const fs=require("fs"), v=JSON.parse(fs.readFileSync("ai/verdict.json","utf8"));
            for(const r of v.results){
              for(const f of (r.findings||[])){
                const lvl = f.severity==="high" ? "error" : (f.severity==="medium" ? "warning" : "notice");
                console.log(`::${lvl} file=${f.path},line=${f.line}::[${r.role}] ${f.title} — ${f.advice}`);
              }
            }
          '

      - name: Fail or pass the check
        run: |
          s=$(jq -r .status < ai/verdict.json)
          echo "AI review status: ${s}"
          if [ "$s" != "pass" ]; then
            echo "Hard fail criteria met (see AI Review Summary)."
            exit 1
          fi
